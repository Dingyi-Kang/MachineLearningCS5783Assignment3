{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GHPraPgL8gZs"
      },
      "outputs": [],
      "source": [
        "## Dingyi Kang\n",
        "## A20308046\n",
        "## Assignment3 - problem 1\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download and load the data into np array\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
        "# normalize the pixel data (to make the value between 0 and 1)\n",
        "train_x = train_images / 255.0\n",
        "test_x = test_images / 255.0\n",
        "train_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDmRRNEa8wVJ",
        "outputId": "469e75b5-c6f2-49f5-8af7-4e0709aa4ba3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildCNNModel(batchSize, optimizerStr, learningRate):\n",
        "  cnn_model = tf.keras.models.Sequential()\n",
        "  #layer 1\n",
        "  cnn_model.add(tf.keras.layers.Conv2D(6, (5, 5), strides=(1, 1),  activation='relu', input_shape=(32,32,3)))\n",
        "  #layer 2\n",
        "  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 3\n",
        "  cnn_model.add(tf.keras.layers.Conv2D(16, (5, 5), strides=(1, 1),  activation='relu'))\n",
        "  #layer 4\n",
        "  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 5\n",
        "  cnn_model.add(tf.keras.layers.Conv2D(120, (5, 5), strides=(1, 1), activation='relu'))\n",
        "  # you need flatten to make the extracted features from above  inputs for the model\n",
        "  cnn_model.add(tf.keras.layers.Flatten())\n",
        "  #layer 6\n",
        "  cnn_model.add(tf.keras.layers.Dense(84))\n",
        "  cnn_model.add(tf.keras.layers.Activation('relu'))\n",
        "  #output layer\n",
        "  cnn_model.add(tf.keras.layers.Dense(10))\n",
        "  cnn_model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "  #compile the model with certain configuration of loss function, optimizer and its learning rate, and result metrics\n",
        "  if optimizerStr == 'Adam':\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learningRate)\n",
        "  elif optimizerStr == 'SGD':\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learningRate)\n",
        "  elif optimizerStr == 'RMSProp':\n",
        "    optimizer = keras.optimizers.RMSprop(learning_rate=learningRate)\n",
        "  elif optimizerStr == 'Adadelta':\n",
        "    optimizer = keras.optimizers.Adadelta(learning_rate=learningRate)\n",
        "  elif optimizerStr == 'Adagrad':\n",
        "    optimizer = keras.optimizers.Adagrad(learning_rate=learningRate)\n",
        "  elif optimizerStr == 'Adamax':\n",
        "    optimizer = keras.optimizers.Adamax(learning_rate=learningRate)\n",
        "  elif optimizerStr == 'Nadam':\n",
        "    optimizer = keras.optimizers.Nadam(learning_rate=learningRate)\n",
        "  elif optimizerStr == 'Ftrl':\n",
        "    optimizer = keras.optimizers.Ftrl(learning_rate=learningRate)\n",
        "    \n",
        "  cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  cnn_model.summary()\n",
        "\n",
        "  # Train the model\n",
        "  cnn_model.fit(\n",
        "      train_x,\n",
        "      train_labels, \n",
        "      batch_size=batchSize,\n",
        "      epochs=25)\n",
        "  # test the model performance\n",
        "  score = cnn_model.evaluate(test_x, test_labels)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "\n",
        "  # return the accuracy score\n",
        "  return score[1]"
      ],
      "metadata": {
        "id": "0z6QnpwrCTni"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. we can first explore the influence of learning rate on the model performance\n",
        "# below is the learning rate we try at the first\n",
        "learningRatesArr = [0.0001, 0.0004, 0.0007, 0.001, 0.002]\n",
        "accuracyArr = []\n",
        "for i in range(len(learningRatesArr)):\n",
        "  a = buildCNNModel(batchSize=512, optimizerStr='Adam', learningRate=learningRatesArr[i])\n",
        "  accuracyArr.append(a)\n",
        "\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel('Model Accuracy')\n",
        "plt.scatter(learningRatesArr, accuracyArr)\n",
        "plt.plot(learningRatesArr, accuracyArr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fU0Q-tP3gxx3",
        "outputId": "da655a8a-0fdc-4ccd-9877-b86e1af0e9bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 120)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                10164     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 84)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 10s 11ms/step - loss: 2.2497 - accuracy: 0.1838\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 2.0255 - accuracy: 0.2766\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.8675 - accuracy: 0.3317\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.8054 - accuracy: 0.3489\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.7641 - accuracy: 0.3648\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.7325 - accuracy: 0.3769\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.7033 - accuracy: 0.3847\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 1.6781 - accuracy: 0.3955\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.6549 - accuracy: 0.4036\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.6333 - accuracy: 0.4101\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.6160 - accuracy: 0.4185\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5968 - accuracy: 0.4234\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5788 - accuracy: 0.4321\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5638 - accuracy: 0.4366\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.5485 - accuracy: 0.4436\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.5334 - accuracy: 0.4483\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.5203 - accuracy: 0.4530\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.5064 - accuracy: 0.4591\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4947 - accuracy: 0.4626\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4850 - accuracy: 0.4660\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4737 - accuracy: 0.4705\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.4668 - accuracy: 0.4749\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.4549 - accuracy: 0.4794\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.4477 - accuracy: 0.4813\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.4388 - accuracy: 0.4850\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4448 - accuracy: 0.4781\n",
            "Test loss: 1.4447699785232544\n",
            "Test accuracy: 0.4781000018119812\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 2.0810 - accuracy: 0.2404\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.7954 - accuracy: 0.3572\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.6440 - accuracy: 0.4080\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5603 - accuracy: 0.4368\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5231 - accuracy: 0.4531\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4750 - accuracy: 0.4725\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.4378 - accuracy: 0.4863\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.4113 - accuracy: 0.4973\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.3821 - accuracy: 0.5089\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.3589 - accuracy: 0.5183\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.3368 - accuracy: 0.5248\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.3139 - accuracy: 0.5341\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.2996 - accuracy: 0.5402\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.2810 - accuracy: 0.5465\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.2644 - accuracy: 0.5529\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.2470 - accuracy: 0.5608\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.2401 - accuracy: 0.5612\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.2222 - accuracy: 0.5679\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.2218 - accuracy: 0.5688\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.2075 - accuracy: 0.5727\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 1.1937 - accuracy: 0.5790\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.1864 - accuracy: 0.5834\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 1.1743 - accuracy: 0.5856\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.1700 - accuracy: 0.5875\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 1.1597 - accuracy: 0.5902\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2012 - accuracy: 0.5729\n",
            "Test loss: 1.2011996507644653\n",
            "Test accuracy: 0.5728999972343445\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.9654 - accuracy: 0.2846\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.6896 - accuracy: 0.3944\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.6018 - accuracy: 0.4249\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5452 - accuracy: 0.4414\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4879 - accuracy: 0.4634\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4551 - accuracy: 0.4759\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4191 - accuracy: 0.4926\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4035 - accuracy: 0.4975\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3687 - accuracy: 0.5117\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3522 - accuracy: 0.5163\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3321 - accuracy: 0.5241\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3049 - accuracy: 0.5357\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2968 - accuracy: 0.5388\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2683 - accuracy: 0.5515\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2502 - accuracy: 0.5557\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2373 - accuracy: 0.5626\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2148 - accuracy: 0.5709\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2083 - accuracy: 0.5741\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1865 - accuracy: 0.5808\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1831 - accuracy: 0.5830\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.1603 - accuracy: 0.5896\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.1478 - accuracy: 0.5947\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.1360 - accuracy: 0.5973\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1225 - accuracy: 0.6034\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1118 - accuracy: 0.6079\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1580 - accuracy: 0.5938\n",
            "Test loss: 1.158003807067871\n",
            "Test accuracy: 0.5938000082969666\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.8857 - accuracy: 0.3140\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.6217 - accuracy: 0.4133\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.5243 - accuracy: 0.4517\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 2s 16ms/step - loss: 1.4510 - accuracy: 0.4800\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 15ms/step - loss: 1.3926 - accuracy: 0.5021\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.3504 - accuracy: 0.5168\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3095 - accuracy: 0.5337\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2726 - accuracy: 0.5468\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2481 - accuracy: 0.5553\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2304 - accuracy: 0.5632\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2084 - accuracy: 0.5708\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1779 - accuracy: 0.5831\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1617 - accuracy: 0.5896\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1469 - accuracy: 0.5958\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1298 - accuracy: 0.6011\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1103 - accuracy: 0.6080\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.1002 - accuracy: 0.6112\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.0853 - accuracy: 0.6157\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0785 - accuracy: 0.6200\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0610 - accuracy: 0.6269\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0446 - accuracy: 0.6294\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.0381 - accuracy: 0.6334\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.0260 - accuracy: 0.6382\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0109 - accuracy: 0.6448\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0030 - accuracy: 0.6486\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1263 - accuracy: 0.6045\n",
            "Test loss: 1.1262844800949097\n",
            "Test accuracy: 0.6044999957084656\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.9040 - accuracy: 0.3024\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5986 - accuracy: 0.4201\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4719 - accuracy: 0.4658\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4038 - accuracy: 0.4942\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3447 - accuracy: 0.5172\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3087 - accuracy: 0.5348\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2658 - accuracy: 0.5500\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2255 - accuracy: 0.5653\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.1945 - accuracy: 0.5768\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 1.1685 - accuracy: 0.5863\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.1410 - accuracy: 0.5982\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1228 - accuracy: 0.6039\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.1098 - accuracy: 0.6097\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.0886 - accuracy: 0.6171\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.0616 - accuracy: 0.6261\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0386 - accuracy: 0.6343\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.0230 - accuracy: 0.6387\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.9938 - accuracy: 0.6499\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9910 - accuracy: 0.6505\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9646 - accuracy: 0.6611\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9545 - accuracy: 0.6648\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.9363 - accuracy: 0.6712\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.9203 - accuracy: 0.6749\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.9028 - accuracy: 0.6803\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9111 - accuracy: 0.6779\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0925 - accuracy: 0.6225\n",
            "Test loss: 1.0924712419509888\n",
            "Test accuracy: 0.6225000023841858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1a24204d50>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# As we can see from the graph, the model with learnign rate of 0.002 did the best with an accuracy of 0.6225\n",
        "# Hence, we will further explore this area"
      ],
      "metadata": {
        "id": "3RZCjnFMtv4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learningRatesArr = [0.0022, 0.0025, 0.0028, 0.0031, 0.0034]\n",
        "accuracyArr = []\n",
        "for i in range(len(learningRatesArr)):\n",
        "  a = buildCNNModel(batchSize=512, optimizerStr='Adam', learningRate=learningRatesArr[i])\n",
        "  accuracyArr.append(a)\n",
        "\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel('Model Accuracy')\n",
        "plt.scatter(learningRatesArr, accuracyArr)\n",
        "plt.plot(learningRatesArr, accuracyArr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p_lXnjyOuFVB",
        "outputId": "79749871-46e1-4afd-e08c-9e65998b91da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.8766 - accuracy: 0.3105\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5424 - accuracy: 0.4403\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4221 - accuracy: 0.4868\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3609 - accuracy: 0.5112\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3242 - accuracy: 0.5287\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2666 - accuracy: 0.5509\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2395 - accuracy: 0.5612\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2032 - accuracy: 0.5736\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1771 - accuracy: 0.5824\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1476 - accuracy: 0.5926\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1349 - accuracy: 0.5989\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0999 - accuracy: 0.6116\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0823 - accuracy: 0.6184\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0484 - accuracy: 0.6289\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0545 - accuracy: 0.6288\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0218 - accuracy: 0.6400\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0108 - accuracy: 0.6448\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9968 - accuracy: 0.6473\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9812 - accuracy: 0.6524\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9633 - accuracy: 0.6608\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9555 - accuracy: 0.6641\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9473 - accuracy: 0.6683\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9215 - accuracy: 0.6754\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9149 - accuracy: 0.6781\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8984 - accuracy: 0.6843\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1057 - accuracy: 0.6153\n",
            "Test loss: 1.1057465076446533\n",
            "Test accuracy: 0.6152999997138977\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.8686 - accuracy: 0.3163\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5283 - accuracy: 0.4472\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4049 - accuracy: 0.4952\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3160 - accuracy: 0.5323\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2708 - accuracy: 0.5488\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2211 - accuracy: 0.5674\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1871 - accuracy: 0.5821\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1535 - accuracy: 0.5919\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1199 - accuracy: 0.6054\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1004 - accuracy: 0.6133\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0762 - accuracy: 0.6227\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0470 - accuracy: 0.6319\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0353 - accuracy: 0.6350\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.0127 - accuracy: 0.6445\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.9940 - accuracy: 0.6523\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.9865 - accuracy: 0.6536\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9596 - accuracy: 0.6635\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9472 - accuracy: 0.6688\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9362 - accuracy: 0.6711\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9184 - accuracy: 0.6778\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9036 - accuracy: 0.6822\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8793 - accuracy: 0.6911\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.8669 - accuracy: 0.6959\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8768 - accuracy: 0.6924\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8464 - accuracy: 0.7032\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0678 - accuracy: 0.6342\n",
            "Test loss: 1.0677587985992432\n",
            "Test accuracy: 0.6341999769210815\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_21 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.8043 - accuracy: 0.3410\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5114 - accuracy: 0.4528\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3981 - accuracy: 0.4983\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3051 - accuracy: 0.5350\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2447 - accuracy: 0.5574\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2004 - accuracy: 0.5742\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1768 - accuracy: 0.5823\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1280 - accuracy: 0.6004\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1147 - accuracy: 0.6064\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0806 - accuracy: 0.6174\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0594 - accuracy: 0.6246\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0312 - accuracy: 0.6343\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0100 - accuracy: 0.6421\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9910 - accuracy: 0.6496\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9768 - accuracy: 0.6506\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9548 - accuracy: 0.6612\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9460 - accuracy: 0.6645\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9290 - accuracy: 0.6700\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9217 - accuracy: 0.6725\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.8924 - accuracy: 0.6826\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 0.8877 - accuracy: 0.6851\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.8737 - accuracy: 0.6897\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8509 - accuracy: 0.6974\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8456 - accuracy: 0.6999\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8291 - accuracy: 0.7044\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1024 - accuracy: 0.6227\n",
            "Test loss: 1.1024155616760254\n",
            "Test accuracy: 0.6226999759674072\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 2s 11ms/step - loss: 1.8825 - accuracy: 0.3159\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5584 - accuracy: 0.4351\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4111 - accuracy: 0.4918\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3241 - accuracy: 0.5267\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2570 - accuracy: 0.5509\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2102 - accuracy: 0.5694\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1646 - accuracy: 0.5864\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1249 - accuracy: 0.6021\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.0746 - accuracy: 0.6193\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.0553 - accuracy: 0.6266\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 1.0282 - accuracy: 0.6355\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.9970 - accuracy: 0.6458\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.9729 - accuracy: 0.6559\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.9473 - accuracy: 0.6637\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.9324 - accuracy: 0.6701\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.9100 - accuracy: 0.6766\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8996 - accuracy: 0.6825\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8733 - accuracy: 0.6933\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8581 - accuracy: 0.6953\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8495 - accuracy: 0.6981\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8261 - accuracy: 0.7072\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 0.8141 - accuracy: 0.7140\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.8067 - accuracy: 0.7154\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.7977 - accuracy: 0.7189\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.7699 - accuracy: 0.7280\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1023 - accuracy: 0.6318\n",
            "Test loss: 1.102265477180481\n",
            "Test accuracy: 0.6317999958992004\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_27 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.8384 - accuracy: 0.3300\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5312 - accuracy: 0.4453\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4019 - accuracy: 0.4944\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3285 - accuracy: 0.5238\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2701 - accuracy: 0.5479\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2142 - accuracy: 0.5679\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1655 - accuracy: 0.5881\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1366 - accuracy: 0.5971\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1079 - accuracy: 0.6055\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0606 - accuracy: 0.6238\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0512 - accuracy: 0.6285\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0204 - accuracy: 0.6387\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9997 - accuracy: 0.6467\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9755 - accuracy: 0.6529\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.9562 - accuracy: 0.6620\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9231 - accuracy: 0.6734\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9058 - accuracy: 0.6792\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.8905 - accuracy: 0.6844\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8805 - accuracy: 0.6869\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8653 - accuracy: 0.6943\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8378 - accuracy: 0.7050\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8401 - accuracy: 0.7045\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8156 - accuracy: 0.7107\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8034 - accuracy: 0.7156\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.7852 - accuracy: 0.7229\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1611 - accuracy: 0.6113\n",
            "Test loss: 1.1611131429672241\n",
            "Test accuracy: 0.611299991607666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1a0c389e90>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From the graph above, we can see the model with learnign rate of 0.0025 did the best with an accuracy of 0.63420"
      ],
      "metadata": {
        "id": "nAsjWJ4-wCFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer to question 1: in summary, we can say the effect of learning rate on the training process is not linear. It gives the model best performance around 0.0028. And the model performed best with the learning rate of 0.0025 at an accuracy of 0.63420"
      ],
      "metadata": {
        "id": "ZejLTEXewbAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. we can explore the influence of batch size on the model performance\n",
        "# below is the batch sizes we try\n",
        "batchSizesArr = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "accuracyArr = []\n",
        "for i in range(len(batchSizesArr)):\n",
        "  a = buildCNNModel(batchSize=batchSizesArr[i], optimizerStr='Adam', learningRate=0.0025)\n",
        "  accuracyArr.append(a)\n",
        "  \n",
        "plt.xlabel(\"Batch Size\")\n",
        "plt.ylabel('Model Accuracy')\n",
        "plt.scatter(batchSizesArr, accuracyArr)\n",
        "plt.plot(batchSizesArr, accuracyArr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AltTPQXQha6t",
        "outputId": "b9f682b3-97bc-4c17-9888-165bcf608216"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "500/500 [==============================] - 3s 4ms/step - loss: 1.6778 - accuracy: 0.3876\n",
            "Epoch 2/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.4033 - accuracy: 0.4941\n",
            "Epoch 3/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.2854 - accuracy: 0.5426\n",
            "Epoch 4/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.2118 - accuracy: 0.5691\n",
            "Epoch 5/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.1560 - accuracy: 0.5890\n",
            "Epoch 6/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.1117 - accuracy: 0.6047\n",
            "Epoch 7/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.0760 - accuracy: 0.6200\n",
            "Epoch 8/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.0445 - accuracy: 0.6294\n",
            "Epoch 9/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.0203 - accuracy: 0.6398\n",
            "Epoch 10/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.9882 - accuracy: 0.6489\n",
            "Epoch 11/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.9658 - accuracy: 0.6580\n",
            "Epoch 12/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.9446 - accuracy: 0.6655\n",
            "Epoch 13/25\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.9245 - accuracy: 0.6723\n",
            "Epoch 14/25\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.9044 - accuracy: 0.6786\n",
            "Epoch 15/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.8900 - accuracy: 0.6847\n",
            "Epoch 16/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.8764 - accuracy: 0.6884\n",
            "Epoch 17/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.8572 - accuracy: 0.6967\n",
            "Epoch 18/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.8430 - accuracy: 0.6979\n",
            "Epoch 19/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.8293 - accuracy: 0.7048\n",
            "Epoch 20/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.8166 - accuracy: 0.7071\n",
            "Epoch 21/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.7997 - accuracy: 0.7139\n",
            "Epoch 22/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.7847 - accuracy: 0.7181\n",
            "Epoch 23/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.7717 - accuracy: 0.7248\n",
            "Epoch 24/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.7608 - accuracy: 0.7274\n",
            "Epoch 25/25\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.7540 - accuracy: 0.7286\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.3663 - accuracy: 0.5837\n",
            "Test loss: 1.3663192987442017\n",
            "Test accuracy: 0.5837000012397766\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_33 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "250/250 [==============================] - 2s 5ms/step - loss: 1.8097 - accuracy: 0.3451\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.4797 - accuracy: 0.4650\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.3726 - accuracy: 0.5076\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.2982 - accuracy: 0.5345\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.2338 - accuracy: 0.5601\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.1902 - accuracy: 0.5738\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.1556 - accuracy: 0.5919\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.1191 - accuracy: 0.6024\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.0988 - accuracy: 0.6103\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.0640 - accuracy: 0.6232\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.0463 - accuracy: 0.6279\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.0288 - accuracy: 0.6347\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 1.0022 - accuracy: 0.6454\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9955 - accuracy: 0.6476\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9664 - accuracy: 0.6577\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9631 - accuracy: 0.6569\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9464 - accuracy: 0.6661\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.6691\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9191 - accuracy: 0.6748\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.9101 - accuracy: 0.6762\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.8885 - accuracy: 0.6845\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.8775 - accuracy: 0.6883\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.8757 - accuracy: 0.6882\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.8667 - accuracy: 0.6909\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.8464 - accuracy: 0.6989\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1818 - accuracy: 0.6057\n",
            "Test loss: 1.1818280220031738\n",
            "Test accuracy: 0.6057000160217285\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "167/167 [==============================] - 2s 8ms/step - loss: 1.7658 - accuracy: 0.3586\n",
            "Epoch 2/25\n",
            "167/167 [==============================] - 2s 10ms/step - loss: 1.4563 - accuracy: 0.4719\n",
            "Epoch 3/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 1.3379 - accuracy: 0.5216\n",
            "Epoch 4/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 1.2654 - accuracy: 0.5507\n",
            "Epoch 5/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 1.2137 - accuracy: 0.5684\n",
            "Epoch 6/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 1.1681 - accuracy: 0.5862\n",
            "Epoch 7/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 1.1192 - accuracy: 0.6038\n",
            "Epoch 8/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 1.0875 - accuracy: 0.6166\n",
            "Epoch 9/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 1.0440 - accuracy: 0.6321\n",
            "Epoch 10/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 1.0160 - accuracy: 0.6408\n",
            "Epoch 11/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.9877 - accuracy: 0.6529\n",
            "Epoch 12/25\n",
            "167/167 [==============================] - 2s 9ms/step - loss: 0.9725 - accuracy: 0.6567\n",
            "Epoch 13/25\n",
            "167/167 [==============================] - 1s 9ms/step - loss: 0.9444 - accuracy: 0.6653\n",
            "Epoch 14/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.9262 - accuracy: 0.6738\n",
            "Epoch 15/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.9126 - accuracy: 0.6774\n",
            "Epoch 16/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.8874 - accuracy: 0.6873\n",
            "Epoch 17/25\n",
            "167/167 [==============================] - 1s 8ms/step - loss: 0.8668 - accuracy: 0.6945\n",
            "Epoch 18/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.8430 - accuracy: 0.7028\n",
            "Epoch 19/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.8252 - accuracy: 0.7086\n",
            "Epoch 20/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.8170 - accuracy: 0.7115\n",
            "Epoch 21/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.8002 - accuracy: 0.7177\n",
            "Epoch 22/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.7827 - accuracy: 0.7239\n",
            "Epoch 23/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.7676 - accuracy: 0.7275\n",
            "Epoch 24/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.7541 - accuracy: 0.7327\n",
            "Epoch 25/25\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.7449 - accuracy: 0.7379\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1386 - accuracy: 0.6257\n",
            "Test loss: 1.1386240720748901\n",
            "Test accuracy: 0.6256999969482422\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_39 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "125/125 [==============================] - 2s 8ms/step - loss: 1.8498 - accuracy: 0.3276\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.5070 - accuracy: 0.4554\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.3963 - accuracy: 0.4967\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.3106 - accuracy: 0.5309\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.2551 - accuracy: 0.5518\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.1920 - accuracy: 0.5770\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.1507 - accuracy: 0.5945\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.1356 - accuracy: 0.5970\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.0968 - accuracy: 0.6101\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.0706 - accuracy: 0.6198\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.0370 - accuracy: 0.6326\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.0224 - accuracy: 0.6379\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1.0003 - accuracy: 0.6459\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.9846 - accuracy: 0.6525\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.9738 - accuracy: 0.6546\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.9570 - accuracy: 0.6637\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.9292 - accuracy: 0.6733\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.9127 - accuracy: 0.6788\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.9068 - accuracy: 0.6807\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.8875 - accuracy: 0.6868\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.8671 - accuracy: 0.6935\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.8657 - accuracy: 0.6946\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.8490 - accuracy: 0.6998\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.8410 - accuracy: 0.7017\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.8311 - accuracy: 0.7050\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1112 - accuracy: 0.6266\n",
            "Test loss: 1.1112184524536133\n",
            "Test accuracy: 0.6266000270843506\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 2s 9ms/step - loss: 1.8340 - accuracy: 0.3175\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.5155 - accuracy: 0.4495\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.3919 - accuracy: 0.4957\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.3231 - accuracy: 0.5252\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.2564 - accuracy: 0.5514\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.2029 - accuracy: 0.5711\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.1570 - accuracy: 0.5875\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.1115 - accuracy: 0.6081\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.0804 - accuracy: 0.6181\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.0526 - accuracy: 0.6288\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.0294 - accuracy: 0.6361\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.0035 - accuracy: 0.6454\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9778 - accuracy: 0.6574\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9627 - accuracy: 0.6580\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9413 - accuracy: 0.6681\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.9132 - accuracy: 0.6767\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.8938 - accuracy: 0.6839\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.8757 - accuracy: 0.6928\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.8569 - accuracy: 0.6962\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.8495 - accuracy: 0.7002\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.8258 - accuracy: 0.7095\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.8259 - accuracy: 0.7071\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.8019 - accuracy: 0.7169\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.7884 - accuracy: 0.7215\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.7706 - accuracy: 0.7274\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1075 - accuracy: 0.6287\n",
            "Test loss: 1.1075385808944702\n",
            "Test accuracy: 0.6287000179290771\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_45 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 2s 12ms/step - loss: 1.8700 - accuracy: 0.3170\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.5906 - accuracy: 0.4211\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4782 - accuracy: 0.4670\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3862 - accuracy: 0.5038\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3290 - accuracy: 0.5261\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2836 - accuracy: 0.5450\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2255 - accuracy: 0.5676\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1935 - accuracy: 0.5785\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1603 - accuracy: 0.5928\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1438 - accuracy: 0.5957\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1253 - accuracy: 0.6028\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0905 - accuracy: 0.6155\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0685 - accuracy: 0.6236\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0522 - accuracy: 0.6295\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0431 - accuracy: 0.6341\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0141 - accuracy: 0.6429\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0026 - accuracy: 0.6468\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9799 - accuracy: 0.6541\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9640 - accuracy: 0.6611\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9484 - accuracy: 0.6660\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9430 - accuracy: 0.6685\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9283 - accuracy: 0.6734\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9144 - accuracy: 0.6782\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9022 - accuracy: 0.6824\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.8876 - accuracy: 0.6858\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1248 - accuracy: 0.6148\n",
            "Test loss: 1.1247833967208862\n",
            "Test accuracy: 0.614799976348877\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_48 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 2s 13ms/step - loss: 1.9146 - accuracy: 0.3022\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.5591 - accuracy: 0.4393\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.4565 - accuracy: 0.4780\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 1.3701 - accuracy: 0.5096\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.3250 - accuracy: 0.5295\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.2901 - accuracy: 0.5424\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.2575 - accuracy: 0.5558\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.2237 - accuracy: 0.5674\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.1940 - accuracy: 0.5779\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.1778 - accuracy: 0.5818\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.1519 - accuracy: 0.5921\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.1247 - accuracy: 0.6032\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.1131 - accuracy: 0.6068\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.0988 - accuracy: 0.6117\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.0711 - accuracy: 0.6219\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.0563 - accuracy: 0.6284\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.0441 - accuracy: 0.6304\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.0374 - accuracy: 0.6356\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.0182 - accuracy: 0.6417\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 1.0040 - accuracy: 0.6480\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.9838 - accuracy: 0.6545\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.9861 - accuracy: 0.6532\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.9785 - accuracy: 0.6544\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.9545 - accuracy: 0.6641\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 1s 13ms/step - loss: 0.9502 - accuracy: 0.6632\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1456 - accuracy: 0.6074\n",
            "Test loss: 1.1456085443496704\n",
            "Test accuracy: 0.6074000000953674\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_51 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "63/63 [==============================] - 2s 14ms/step - loss: 1.9011 - accuracy: 0.3094\n",
            "Epoch 2/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.5690 - accuracy: 0.4334\n",
            "Epoch 3/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.4486 - accuracy: 0.4760\n",
            "Epoch 4/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.3846 - accuracy: 0.5028\n",
            "Epoch 5/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.3321 - accuracy: 0.5214\n",
            "Epoch 6/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.2925 - accuracy: 0.5415\n",
            "Epoch 7/25\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 1.2562 - accuracy: 0.5537\n",
            "Epoch 8/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.2198 - accuracy: 0.5697\n",
            "Epoch 9/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.1861 - accuracy: 0.5798\n",
            "Epoch 10/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.1544 - accuracy: 0.5914\n",
            "Epoch 11/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.1375 - accuracy: 0.5983\n",
            "Epoch 12/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.1224 - accuracy: 0.6037\n",
            "Epoch 13/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.1039 - accuracy: 0.6111\n",
            "Epoch 14/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.0769 - accuracy: 0.6207\n",
            "Epoch 15/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.0774 - accuracy: 0.6210\n",
            "Epoch 16/25\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.0548 - accuracy: 0.6272\n",
            "Epoch 17/25\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 1.0286 - accuracy: 0.6354\n",
            "Epoch 18/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 1.0128 - accuracy: 0.6430\n",
            "Epoch 19/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.9890 - accuracy: 0.6498\n",
            "Epoch 20/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.9949 - accuracy: 0.6493\n",
            "Epoch 21/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.9730 - accuracy: 0.6560\n",
            "Epoch 22/25\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.9578 - accuracy: 0.6623\n",
            "Epoch 23/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.9526 - accuracy: 0.6645\n",
            "Epoch 24/25\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.9506 - accuracy: 0.6629\n",
            "Epoch 25/25\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.9312 - accuracy: 0.6719\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1089 - accuracy: 0.6125\n",
            "Test loss: 1.108930230140686\n",
            "Test accuracy: 0.612500011920929\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_54 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "56/56 [==============================] - 2s 15ms/step - loss: 1.9696 - accuracy: 0.2776\n",
            "Epoch 2/25\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.6487 - accuracy: 0.4013\n",
            "Epoch 3/25\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.5219 - accuracy: 0.4527\n",
            "Epoch 4/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.4297 - accuracy: 0.4851\n",
            "Epoch 5/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.3875 - accuracy: 0.5023\n",
            "Epoch 6/25\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.3406 - accuracy: 0.5189\n",
            "Epoch 7/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.3139 - accuracy: 0.5329\n",
            "Epoch 8/25\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.2831 - accuracy: 0.5449\n",
            "Epoch 9/25\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.2383 - accuracy: 0.5605\n",
            "Epoch 10/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.2140 - accuracy: 0.5700\n",
            "Epoch 11/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.1882 - accuracy: 0.5791\n",
            "Epoch 12/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.1651 - accuracy: 0.5901\n",
            "Epoch 13/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.1490 - accuracy: 0.5925\n",
            "Epoch 14/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.1259 - accuracy: 0.6011\n",
            "Epoch 15/25\n",
            "56/56 [==============================] - 1s 19ms/step - loss: 1.1149 - accuracy: 0.6068\n",
            "Epoch 16/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.0946 - accuracy: 0.6124\n",
            "Epoch 17/25\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 1.0739 - accuracy: 0.6222\n",
            "Epoch 18/25\n",
            "56/56 [==============================] - 1s 19ms/step - loss: 1.0547 - accuracy: 0.6269\n",
            "Epoch 19/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.0384 - accuracy: 0.6348\n",
            "Epoch 20/25\n",
            "56/56 [==============================] - 1s 17ms/step - loss: 1.0285 - accuracy: 0.6363\n",
            "Epoch 21/25\n",
            "56/56 [==============================] - 1s 22ms/step - loss: 1.0268 - accuracy: 0.6369\n",
            "Epoch 22/25\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 1.0029 - accuracy: 0.6467\n",
            "Epoch 23/25\n",
            "56/56 [==============================] - 1s 18ms/step - loss: 0.9799 - accuracy: 0.6551\n",
            "Epoch 24/25\n",
            "56/56 [==============================] - 1s 19ms/step - loss: 0.9798 - accuracy: 0.6561\n",
            "Epoch 25/25\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 0.9662 - accuracy: 0.6592\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1213 - accuracy: 0.6085\n",
            "Test loss: 1.121325135231018\n",
            "Test accuracy: 0.6085000038146973\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_57 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "50/50 [==============================] - 2s 17ms/step - loss: 1.9288 - accuracy: 0.2962\n",
            "Epoch 2/25\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 1.6317 - accuracy: 0.4057\n",
            "Epoch 3/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.5357 - accuracy: 0.4432\n",
            "Epoch 4/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.4757 - accuracy: 0.4658\n",
            "Epoch 5/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.4124 - accuracy: 0.4914\n",
            "Epoch 6/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.3694 - accuracy: 0.5057\n",
            "Epoch 7/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.3287 - accuracy: 0.5247\n",
            "Epoch 8/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.3010 - accuracy: 0.5370\n",
            "Epoch 9/25\n",
            "50/50 [==============================] - 1s 19ms/step - loss: 1.2668 - accuracy: 0.5487\n",
            "Epoch 10/25\n",
            "50/50 [==============================] - 1s 19ms/step - loss: 1.2342 - accuracy: 0.5613\n",
            "Epoch 11/25\n",
            "50/50 [==============================] - 1s 19ms/step - loss: 1.2110 - accuracy: 0.5698\n",
            "Epoch 12/25\n",
            "50/50 [==============================] - 1s 19ms/step - loss: 1.1760 - accuracy: 0.5850\n",
            "Epoch 13/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.1724 - accuracy: 0.5850\n",
            "Epoch 14/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.1487 - accuracy: 0.5929\n",
            "Epoch 15/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.1240 - accuracy: 0.6037\n",
            "Epoch 16/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.0962 - accuracy: 0.6125\n",
            "Epoch 17/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.0773 - accuracy: 0.6199\n",
            "Epoch 18/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.0676 - accuracy: 0.6224\n",
            "Epoch 19/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.0519 - accuracy: 0.6292\n",
            "Epoch 20/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.0512 - accuracy: 0.6277\n",
            "Epoch 21/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.0309 - accuracy: 0.6347\n",
            "Epoch 22/25\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 1.0111 - accuracy: 0.6427\n",
            "Epoch 23/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 1.0085 - accuracy: 0.6450\n",
            "Epoch 24/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 0.9884 - accuracy: 0.6514\n",
            "Epoch 25/25\n",
            "50/50 [==============================] - 1s 17ms/step - loss: 0.9720 - accuracy: 0.6566\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1031 - accuracy: 0.6148\n",
            "Test loss: 1.103132724761963\n",
            "Test accuracy: 0.614799976348877\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1a0d425d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dXA8d/JQhLWAAlIWGQLCAqyhF0QKQKiVWsVl9q6FbRq1bdKK61t39pWbbG1+tYuuLTuiooYQMEF3FFJgLCHHbOxE9YkZDnvH3ODkzAJkzCTO5k5389nPsxdZubMcDNn7vPc5zyiqhhjjDHVRbkdgDHGmNBkCcIYY4xPliCMMcb4ZAnCGGOMT5YgjDHG+BTjdgCBkpSUpF27dnU7DGOMaVQyMzP3qmqyr21BTRAiMgl4HIgGnlbVR3zsMwX4X0CBLFW9TkTOBN7Cc4YTC/yfqv6rttfq2rUrGRkZAX4HxhgT3kRkR03bgpYgRCQaeBK4EMgFlolIuqqu89onFZgBjFLVAyLSztlUAIxQ1RIRaQ6scR6bH6x4jTHGVBXMPoihwGZV3aqqx4FXgcuq7TMVeFJVDwCo6m7n3+OqWuLsExfkOI0xxvgQzC/ejkCO13Kus85bL6CXiHwuIl86TVIAiEhnEVnlPMef7OzBGGMaltu/zGOAVGAscC3wlIgkAqhqjqr2B3oCN4hI++oPFpFpIpIhIhl79uxpwLCNMSb8BTNB5AGdvZY7Oeu85QLpqlqqqtuAjXgSxgnOmcMaYHT1F1DVWaqapqppyck+O+GNMcbUUzATxDIgVUS6iUgT4Bogvdo+c/GcPSAiSXianLaKSCcRSXDWtwbOA7KDGKsxJ5m7Io9Rjyym2/0LGPXIYuauqP77xpjwFrSrmFS1TETuBBbhucz1WVVdKyIPAhmqmu5smyAi64ByYLqq7hORC4G/iIgCAjyqqquDFasx1c1dkceMOaspKi0HIK+wiBlzPIfg5QOrd6UZE54kXMp9p6WlqY2DMIEy8uEPyT9YfNL6jokJfH7/OBciMiY4RCRTVdN8bQubkdTGnK6Dx0r5YstePtm012dyAMgvLGrgqIxxjyUIE7FKyytYmVPIpxv38MmmvazKLaRCoUVcDPGxURSXVpz0mJTEBBciNcYdliBMxFBVtu87xmebPAlh6ZZ9HCkpI0pgQOdE7hyXypjUJM7tnMiCVQVV+iAA4mOimD6xt4vvwJiGZQnChDXvZqNPN+0h94CniahT6wQuHZDCmNQkRvRIolVCbJXHVXZEz1yUTZ7TrDSwS2vroDYRxRKECSu1NRuN6NGWW8/vweieSZzZtikiUutzXT6w44mE8Lt5a3nui+1k7zxM7zNaNMRbMcZ1liBMo6aq7Nh3jE99NBudW63ZKDa6/sN+7hqXyhuZuTz87nr+e9PQAL4DY0KXJQgTcuauyGPmomzyC4tISUxg+sTeVZp2/Go26p5Eq6axNb1EnbVu1oSfjuvJQ+9s4LNNezkvNSlgz21MqLJxECakVB+gBp7O4WljuoMIn27aQ1aOp9moeVwMI3u0ZXSvZL+bjU5HcWk54//6MS3iY5n/0/OIjgreaxnTUGwchGk0/rxwQ5XkAFBcVsETizcHvNmoruJjo/n5pLO465UVvLUijysHd2qw1zbGDZYgTIM6WlJGfmEReYVF5BcWk19YdGK54GBxjQPUAFb8ekJAm43q47v9O/DMp1t5dFE2F/frQEKTaFfjMSaYLEGYE07V9n8qZeUV7D5cUvUL/0QC8Nw/WFRa5THRUcIZLeNJSYxnQOdE9h89zpGSspOeu2NiguvJAUBE+OXkPlw960ue/Xwbd1zQ0+2QjAkaSxAG8K843aHi0pO+8L+9FbPzUDHlFVX7tFolxNKhVTwdExNIO7M1KYkJpCR6llMSE2jXIo4Yr2YiX30QCbHRITVAbVj3tkzo255/LNnMlLTOJLeIczskY4LCOqkNAKMeWXxiQJi3uJgozmzblPzC4pN+2cdGC2e0iielVcKJL3zvBNAhMYHmcXX/DXK6ZzINYeueI0x47BOuGdqZP1zez+1wjKk366Q2p1RTEbqSsgq6tm3GyB5JXknAkwCSmscRFYQrebwHqIWq7snNuW5YF1766htuHNmVnu1s8JwJP5YgDOApQufrDKJjYgKzfuTzx0XEu/s7qcxZnscj727g6RuGuB2OMQHn9pzUJkRMn9ibJtUuGQ21tv9Q07Z5HLdf0IMP1u9m6ZZ9bodjTMBZgjCAp1mn1xnNqWwx6piYwMNX9Av5ph633TyqGymt4nnonfVUVIRHf54xlayJyQCw+3Ax6wsOM3VMd2Zc1MftcBqN+Nho7pvYm5/NziI9K98SqgkrdgZhAHhreR7lFcpVgzu7HUqjc/mAjpyd0pKZi7IprjYK3JjGzBKEQVWZnZFD2pmt6dmuudvhNDpRUcKvJvchr7CI/36x3e1wjAkYSxCG5d8cYMueo0wZYmcP9TWyZxLfOasdTy7ezP6jx90Ox5iAsARhmL0sl2ZNorm4Xwe3Q2nUZkw+i2Ol5Tzx4Sa3QzEmICxBRLijJWXMX5XPJf1TaFaPUc/mWz3bteDqIZ158csdbN1zxO1wjDltliAi3ILVBRw9Xs6UIVa6OhDuGZ9KXEwUf1q4we1QjDltliAi3OxlOfRIbsagLq3dDiUstGsRz23n92DR2l0s277f7XCMOS2WICLY5t1HyNhxgClpnYM6E1uk+fHo7rRvGccfFqwnXIphmshkCSKCvZ6ZQ3SUcMUga14KpIQm0dw7oTdZOYXMX1XgdjjG1JsliAhVWl7Bm5l5jDurnc1nEATfH9SJs85owZ8WbqCkzAbPmcbJEkSE+ih7D3uPlHB1mo19CIboKOFXF/ch90ARLyzd4XY4xtSLJYgI9dqyHJJbxDG2d7LboYSt0anJnN8rmSc+3EThMRs8ZxofSxARaPfhYpZk7+b7gzpVme7TBN4vJ/fhSEkZ/7d4s9uhGFNn9u0QgeZUFuZLs87pYOt9RguuGtyZ55duZ8e+o26HY0ydWIKIMJWF+YZ0bU2PZCvM1xB+NqEXMVFR/HlhttuhGFMnliAiTOaOA2zdc5SrrHO6wbRvGc+0Md1ZsLqAzB0H3A7HGL9Zgogwry3LscJ8Lpg2pjvJLeJ46B0bPGcaj6AmCBGZJCLZIrJZRO6vYZ8pIrJORNaKyMvOugEistRZt0pErg5mnJHiSEkZC1YX8N1zrTBfQ2sWF8PPLuxF5o4DLFyz0+1wjPFL0BKEiEQDTwIXAX2Ba0Wkb7V9UoEZwChVPRu4x9l0DPiRs24S8DcRSQxWrJFiwap8jh0vt+Yll1w1uBO92jfnkYUbOF5W4XY4xpxSMM8ghgKbVXWrqh4HXgUuq7bPVOBJVT0AoKq7nX83quom534+sBuwC/ZP0+yMXHq2a86gLpZr3RATHcWMyX3Yse8YL35pg+dM6AtmgugI5Hgt5zrrvPUCeonI5yLypYhMqv4kIjIUaAJs8bFtmohkiEjGnj17Ahh6+Nm8+zCZOw4wJa2TFeZz0dheyZzXM4knFm/iYFGp2+EYUyu3O6ljgFRgLHAt8JR3U5KIdABeAG5S1ZPOyVV1lqqmqWpacrKdYNTm9YxcYqKE7w20sQ9uEhFmTD6Lg0Wl/GOJDZ4zoS2YCSIP8G7s7uSs85YLpKtqqapuAzbiSRiISEtgAfArVf0yiHGGvdLyCt5cnmuF+ULE2SmtuGJgJ/7z+XZy9h9zOxxjahTMBLEMSBWRbiLSBLgGSK+2z1w8Zw+ISBKeJqetzv5vAc+r6htBjDEiLNmwm71HjnP1EOucDhX3TeyFCMxcZIPnTOgKWoJQ1TLgTmARsB6YraprReRBEbnU2W0RsE9E1gFLgOmqug+YAowBbhSRlc5tQLBiDXezM3Jo1yKO83tZM1yo6NAqgamju5OelU9WTqHb4Rjjk4TLoJ20tDTNyMhwO4yQs/tQMSMeWcy0Md35xaSz3A7HeDlSUsbYmUvontyc16YNt4sHjCtEJFNV03xtc7uT2gTZm5WF+QZb53SoaR4Xw93je/H1tv28v26X2+EYcxJLEGFMVXk9I4ehXdvQ3QrzhaRrhnSmR3IzHnl3A6XlNnjOhBZLEGEsY8cBtu49amW9Q1hsdBQzLurD1r1HeeXrb9wOx5gqLEGEsROF+fpbYb5Q9p0+7RjevQ1/+2ATh4pt8JwJHZYgwtSRkjIWrPIU5mvaxArzhTIR4VeT+7L/6HH+9dFJBQOMcY0liDA1PyufotJyptjYh0ahX6dWXD4ghWc+20ZeYZHb4RgDWIIIW7Mzckht15yBna0wX2Nx38TeKPAXGzxnQoQliDC0efdhln9TyJS0znZtfSPSqXVTbh7VjbdW5rEm76Db4RhjCSIcza4szDeoevFcE+puv6AHiQmx/HGBzTxn3GcJIsyUllcwZ3ku3+nTjqTmVpivsWkZH8vd30ll6dZ9LMne7XY4JsJZgggzi60wX6N33bAz6ZbUjIfe2UCZDZ4zLrIEEWZmL/MU5huTaoX5GqsmMVH8YtJZbN59hNcyck79AGOCxBJEGNl1qJgl2bu5cnAnYqLtv7Yxm3h2e4Z0bc1j72/iSEmZ2+GYCGXfImHkzeW5VChclWbNS42diPDLyX3Ye6SEWR/b4DnjDhtiGyY8hflyGdqtDd2SmrkdjgmAgV1ac0n/Dvzz4y3Mzshl16FiUhITmD6xN5cPtCvUDMxdkcfMRdnkFxYF5diwM4gwsWz7AbbtPcoUO3sIKwM7J1Jaruw8VIwCeYVFzJizmrkrqs/eayLN3BV5zJizmrzCoqAdG5YgwsRry3JoHhfD5H5nuB2KCaBnP99+0rqi0nKbqtQwc1E2RaXlVdYF+tg4ZYIQkZ+KSOuAvaIJuMPFpbyzuoDvntvBCvOFmfwa6jLVtN5EjppqdgXy2PDnDKI9sExEZovIJLHaDSFn/qoCT2E+a14KOymJCXVabyLD8bIKmjaJ9rktkMfGKROEqj4ApALPADcCm0TkIRHpEbAozGmpLMw3wArzhZ3pE3uTEHvyF4ENhIxce4+U8IOnv+TY8XJioqr+Xk+IjWb6xN4Bey2/+iDUUxRmp3MrA1oDb4jInwMWiamXTbsOs+KbQq4eYoX5wtHlAzvy8BX96JiYgADtW8TRplkTnvpkKxnb97sdnmlga/MPctnfP2d13kGeuHYgj1517oljo2NiAg9f0S+gVzGdssFaRO4GfgTsBZ4GpqtqqYhEAZuAnwcsGlNnszNyPIX57LLHsHX5wI5V/ujzC4u4/umv+OEzX/PMDWmM7JnkYnSmoSxYVcC9r6+kddMmvH7rSPp1agUQ1Eue/TmDaANcoaoTVfV1VS0FUNUK4JKgRWZO6XhZBXOW5zG+T3vaWmG+iJGSmMCrtw6nc5sEbvrvMivqF+YqKpS/vpfNHS8v5+yUVrx956gTySHY/EkQ7wInzmVFpKWIDANQ1fXBCsyc2uINu9h31ArzRaJ2LeJ5ddoIerZrzrTnM1i4ZqfbIZkgOFJSxm0vZvLE4s1MSevEy1OH0a5FfIO9vj8J4p/AEa/lI84647LZGbm0bxnH6FRrYohEbZo14eWpwzmnYyvueHk5b68M/8Fzc1fkMeqRxXS7fwGjHlkc1gMGv9l3jO//4ws+3LCb3363L3/6fn/iYnxfuRQs/iQIUa+ZS5ymJbvY3mU7DxbzkRXmi3itEmJ54ZZhpJ3ZmnteW8nsZeFb/bUhRg6Hii+27OXSJz9j56FinrtpKDeN6ubKRSj+fLNsFZG7RCTWud0NbA12YKZ2JwrzDbbmpUjXPC6G/940lPN6JvHzN1fx/NLtbocUFA0xcthtqsrzS7fzw2e+Jql5HG/fMYrzXGwh8CdB3AaMBPKAXGAYMC2YQZnaeQrz5TCsWxu6WmE+AyQ0iebpG9IY36c9v3l7LbM+Cb8KsDWNEK5pRHFjc7ysgl++tZrfvL2Wsb2Seev2ka7/ffszUG63ql6jqu1Utb2qXqeqdtmEi77etp/t+47ZyGlTRVxMNP+8fhAX9+/AQ+9s4PEPNoXNvNZHS8pqHDkcEyW8t3Zno36vlYPfXvk6h9vH9mDWj9JoER/rdlh+jYOIB24BzgZOdJ+r6s1BjMvU4rWMysJ8HdwOxYSY2OgonrhmIPEx0Tz2wUaKSsv5xaTejXoQ5Reb9/LzN1dx7Hg50VFCecW3iSA2WkhMaMK0FzI5t3Mi903oxXk9kxrV+12bf5Bpz2ey90gJj18zgMsGhM6YJn+amF4AzgAmAh8DnYDDwQzK1OzbwnwpJNTwi8pEtugoYeaV/bl+eBf+9fEWfjdvHRUVje/X9eHiUn751mque/orYqOjeP22Efyl2sjhmVeey9IZ4/jz9/uz93AJP3zma66Z9WWjGWW+YFUBV/5zKRWqvHHbyJBKDuDf1Ug9VfUqEblMVZ8TkZeBT4MdmPFtXlYBxaUVNvbB1CoqSvj9ZecQFxPNM59to7i0nD9+rx/RUY3jl/Wnm/Zw/5uryT9YxNTR3bh3Qm/iY6NJ6+p75PCUIZ25bGAKr36dw9+XbObKfy1lbO9k7pvQm3M6NsygsrqoqFD+9sFGnli8mUFdEvnXDwc36PgGf/mTIEqdfwtF5Bw89ZjaBS8kU5vZGTn0at+ccxtoJKVpvESEBy7uQ9Mm0fzf4s0Ul5bz6FXnhvRl0YeKS3lowXpeXZZDj+RmvHHbSAaf6d9sA3Ex0dwwsitT0jrz3NLt/OvjLVzyf59x0Tln8LMLe5HavkVwg/fTkZIyfvbaSt5bt4urBnfiD987p8HHN/jLnwQxy5kP4gEgHWgO/DqoURmfNu46zMqcQh64uE+jamM17hGRE7++Zy7KpqSsgsevGUiTmNBLEh9l72bGnNXsOlTMbef34J7xqcT7qGR7KglNornt/B5cN6wLz3y6jWc+28aitTu5fEBH7hnfiy5tmwYhev98s+8YU5/PYNPuw/zmkr7cNKprSP8t15ognIJ8h1T1APAJ0L1BojI+vbYsh9hoK8xn6u6OC3oSHxvN7+evo+TFTP7xg0H1+vINhoNFpfxh/jpez8wltV1z/nn7qICUrm8ZH8v/XNiLG0Z25d8fb+G5pdtJz8pnypDO/HRcTzq0atg5Nb7YspfbX1qOKjx381BGpyY36OvXR60/I5xR0/Wu1upMMJQtIptF5P4a9pkiIutEZK3Tv1G5fqGIFIrI/Pq+fjg5XlbBWyusMJ+pv1vO68Yfv3cOS7J38+PnMjh2vMztkFi8YRcTHvuYOSvyuOOCHsy/67yAz2vSplkTZkzuwyfTL+C6YV14PSOH82d+xO/nr2PvkZKAvpYvqsoLS6sOfmsMyQE8ZTRq30HkETylvl8DjlauV9VaLxMQkWhgI3AhngF2y4BrVXWd1z6pwGxgnKoeEJF2lWMsROQ7QFPgVlU9ZdXYtLQ0zcjIONVujda7qwv4yUvL+c9NQ7igt3UBmfp7MzOX6W9kMfjM1jx74xBXrrcvPHacB+etY86KPHq3b8GjV53bYBVKc/Yf44kPN/Hm8lziY6O5eVQ3po7pTquEwH8Ox8sq+G36Wl75+hvGndWOx68ZEBLjG7yJSKaqpvnc5keC2OZjtapqrc1NIjIC+F9Vnegsz3Ae+LDXPn8GNqrq0zU8x1jgPksQcNN/vmZ9wWE+v39co7kSxYSuBasKuPvVFZyd0pLnbh5KYtMmDfba76/bxS/fWs2Bo8e5fWwP7hyX6kqfyJY9R3js/Y3MX1VAy/gYbj2/BzeO7EqzuMCUmtt7pITbX1zO19v385OxPbhvQu+Q/NutLUGc8pNQ1W71fN2OgHflsMoyHd56OQF+DkTjSSgL/X0BEZmGU/ajS5cu9Qwz9O08WMzHG/dw+9ieIXmAmcbn4v4diIuJ4vaXlnPtU1/xwi1DSQpy0+WBo8f53by1zF2ZT58OLfnPjUNcvQS1R3Jz/n7dIG4fe4i/vp/NzEXZ/OfzbfxkbE9+MKzLafXRhPLgt7rwZyT1j3ytV9XnA/T6qcBYPAPwPhGRfqpa6M+DVXUWMAs8ZxABiCcknSjMl9bJ7VBMGBnftz3P3JjG1OczuGbWl7z042G0bxmca/EXringgblrKTx2nHvGp3L72J4hcyVV35SWPH3DEJZ/c4C/vJfN7+ev4+lPt/LTcalcldaJ2DpeFrxgVQH3vZ5Fq4RYXr9tBP07Nd654v1550O8bqOB/wUu9eNxeYD3aK5OzjpvuUC6qpaq6jY8fRapfjx3xKioUGZn5DC8exvObGuF+UxgjU5N5rmbhlJQWMSUfy8l98CxgD7/viMl3Pnycm57cTntW8aRfud53DO+V8gkB2+DurTmpR8P5+Wpw+jQKp5fvrWa8X/9mLdW5FYp71GTigrlr+9v5I6Xl9OnQwvSfzqqUScH8K9Y30+9blOBQXjGQpzKMiBVRLqJSBPgGjzjKLzNxXP2gIgk4WlyslLiXr7evp8dVpjPBNGw7m158cfDOHD0OFf/+0u27z166gf5YcGqAiY89gmL1u7k3gt7MfeOUfRNaRmQ5w6mkT2SePMnI3n2xjSaNYnhf17LYtLfPmHhmoIaCwIeLSnjJy9l8sSHm7hycCdemTY8JEdG11V9emOOAqfsl1DVMhG5E1iEp3/hWVVdKyIPAhmqmu5smyAi64ByYLqq7gMQkU+Bs4DmIpIL3KKqi+oRb6M2e1kOLeJiuOgcK8xngmdgl9a8PHU4P3zmK6b8eykvTx1Gz3b1G3m890gJv3l7De+s3km/jq14+arh9D4jNEYx+0tEGHdWe8b2ase7a3by1/ezue3F5fTr2Ip7J/TiwNHjPPreRvILi2jXIo6oKGHXoWJ+fUlfbg7xwW914c9VTPOAyp2igL7AbFX1Oa7BLeF4FdOh4lKG/vEDrhjUiYe+18/tcEwE2LjrMD94+isqKpQXbhlWp1/8qsq8VQX89u01HC0p554LU5k2untIl/bwV1m5ZxzS4x9uIvdAEVEC1Vudbju/O/df1MedAE9DbVcx+fM/9yjwF+f2MDAm1JJDuJqXle8pzGfNS6aB9Grfgtm3jiAuJoprn/qSlTl+XS/C7sPF3PZiJne9soIubZux4K7zuH1sz7BIDgAx0VFcldaZxfeOpVVC7EnJATyFNMONP/973wBfqerHqvo5sE9EugY1KgN4mpd6t29BfyvMZxpQt6RmvHbrCFomxHD901+xrJbS2arK3BV5THjsE5Zk72HGRWfx5m0jQqYwXqA1iYniUFGpz201zXjXmPmTIF4HKryWy511Jog27DxEVu5BpgzpHDbtmabx6NymKa/fOpJ2LeP40TNf8/nmvSfts+tQMVOfz+Ce11bSPakZ79w1mlvP7xE2Zw01SUn0XcOppvWNmT+d1DGqerxyQVWPO1clmSCavSzXCvMZV53RKp7Xpo3gh898xU3/XcYNI87kndU7ySssonXTWIpLK6hQ5YGL+3DTqG4RM4hz+sTezJizmqLS8hPrEmKjmT6xt4tRBYc/qX6PiJwY9yAil+GpzWSCxFOYL5cL+7anTTPLxcY9yS3ieGXqcNq3iOOpT7eR5zSjHDhWSklZOfdO6MWPR3ePmOQAngmLHr6iX5WZ7R6+op/PiYwaO3/OIG4DXhKRvzvLuYDP0dUmMD5Yv4sDx0q5yjqnTQho3awJZT56ZSsUnvtiB9PG9HAhKnddPrBjWCaE6vypxbQFGC4izZ3lI0GPKsLNzsihQ6t4xjSSksAm/O08WOxzfTh2zJpvnbKJSUQeEpFEVT2iqkdEpLWI/KEhgotEBQeL+GTjHq4c3CmiTttNaIukjlnzLX/6IC7yLp7nzC43OXghRbY3M53CfIOtecmEjukTe5NQrbppuHbMmm/50wcRLSJxqloCICIJgE1pFgSewny5jOje1tV5c42prrK9feaibPILi0hJTGD6xN4R0Q4fyfxJEC8BH4rIf5zlm4BAlPo2jrkr8pi5KPvEFSJjUpNcjsiYk0VKx6z5lj+d1H8SkSxgvLPq95FYNC9Y5q7IO+ma6jcyc0nr2sb+GI0xrvJryKOqLlTV+4DfAu1EZEFww4ocMxdlV0kOAMVlFcxclO1SRMYY4+HPVUxNROR7IvI6UACMA/4V9MgiRE2XCdrlg8YYt9WYIERkgtPvsA34Pp5+h/2qepOqzmuoAMOdXT5ojAlVtZ1BLAS6A+ep6vVOUqioZX9TD9Mn9ia+2vSLdvmgMSYU1JYgBgFLgQ9E5H0RuQXPzHAmgC4f2JFJ55xxYjmc67oYYxqXGq9iUtWVwErgfhEZCVwLxIrIu8BbqjqrgWIMe9v2HuXslJYsuGu026EYY8wJ/l7F9IWq/hToBDwGDA9qVBFk296jZOUe5LIBKW6HYowxVfgzUO4EVa0A3nNuJgDmZeUjAt891xKEMSa0hPfUTyFOVXl7ZR5DurahQyu7askYE1osQbhoXcEhtuw5as1LxpiQVGMTk4i0qe2BqlrzTObGL+kr84mJEiaf08HtUIwx5iS19UFkAgr4mpRA8YyRMPVUUaGkZ+UzplcyrW1aUWNMCKrtMtduDRlIpMnYcYCCg8Xcf9FZbodijDE++VOLSUTkehH5tbPcRUSGBj+08Pb2yjziY6MY36e926EYY4xP/nRS/wMYAVznLB8GngxaRBGgtLyCd1YXcGHfM2gWV6crjY0xpsH48+00TFUHicgK8Ew5KiLWaH4aPtu0lwPHSrnUxj4YY0KYP2cQpSISjadjGhFJxor2nZa3V+bRKiGW83slux2KMcbUyJ8E8QTwFp6Jgv4IfAY8FNSowljR8XLeW7eLyf3OoEmMDUMxxoQuf6YcfUlEMoHv4Lnk9XJVXR/0yMLUB+t3cex4uZXWMMaEPH8Hyu0GXvHeZgPl6ic9K5/2LeMY1q2t26EYY0yt/B0o1wU44NxPBL4BbJxEHR08VspH2bv50YiuREf5Gn9ojDGho8ZGcFXtpqrdgQ+A76pqkqq2BS7BqrnWy7trCigtV6u9ZIxpFPzpJR2uqu9ULqjqu8DI4IUUvtKz8unatin9OrZyOxRjjDklfxJEvog8ICJdnduvgB46beIAAA7aSURBVHx/nlxEJolItohsFpH7a9hnioisE5G1IvKy1/obRGSTc7vBv7cTunYdKmbp1n1cOqAjIta8ZIwJff4MlLsW+C2eS10BPnHW1coZO/EkcCGQCywTkXRVXee1TyowAxjlDMBr56xv47xmGp5+kEznsQf8fmchZv6qAlSxwXHGmEbDn8tc9wN3i0gLz6Ie8fO5hwKbVXUrgIi8ClwGrPPaZyrwZOUXv6rudtZPBN6vvFJKRN4HJuF1JVVjk74yj7NTWtKzXXO3QzHGGL/4U6yvn1NmYw2wVkQyReQcP567I5DjtZzrrPPWC+glIp+LyJciMqkOj0VEpolIhohk7Nmzx4+Q3LHd5p02xjRC/vRB/Bv4maqeqapnAvcCswL0+jFAKjAWT7PVUyKS6O+DVXWWqqapalpycuiWrUjP8nTZXNLfEoQxpvHwJ0E0U9UllQuq+hHQzI/H5QGdvZY7Oeu85QLpqlqqqtuAjXgShj+PbRQq550e2q0NKYk277QxpvHwJ0FsFZFfe13F9ACw1Y/HLQNSRaSbU/31GiC92j5z8Zw9ICJJeJqctgKLgAki0lpEWgMTnHWNjs07bYxprPxJEDcDycAc55bsrKuVqpYBd+L5Yl8PzFbVtSLyoIhc6uy2CNgnIuuAJcB0Vd3ndE7/Hk+SWQY82FhLe9i808aYxkpU1e0YAiItLU0zMjLcDqOKigrlvD8t5qwOLXn2xiFuh2OMMScRkUxVTfO1rbZifdWbg6pQ1Utr2248807nHyzm55Ns3mljTONT2ziIEXguNX0F+ApPoT5TB5XzTl/Y1+adNsY0PrUliDPwjIK+Fs981AuAV1R1bUME1tjZvNPGmMautmqu5aq6UFVvAIYDm4GPROTOBouuEbN5p40xjV2tP21FJA64GM9ZRFe+nX7UnEJ6Vr7NO22MadRq66R+HjgHeAf4naquabCoGrmi4+UsWruTS89NsXmnjTGNVm1nENcDR4G7gbu8SlQLnqJ9LYMcW6NVOe/0pTY4zhjTiNWYIFTVfvrWU3pWPu1a2LzTxpjGzZJAgFXOO/3dc1Ns3mljTKNmCSLAFq61eaeNMeHBEkSAvb3S5p02xoQHSxABtNvmnTbGhBFLEAE0z+adNsaEEUsQAWTzThtjwokliACxeaeNMeHGEkSA2LzTxphwYwkiAGzeaWNMOLIEEQCV805b57QxJpxYggiAE/NO97N5p40x4cMSxGmqqFDmZeUzOjWJNs2auB2OMcYEjCWI01Q57/RlAzq6HYoxxgSUJYjTlJ5l804bY8KTJYjTUFpewYJVBYzv097mnTbGhB1LEKehct5pa14yxoQjSxCnIT0rn5bxMYzpleR2KMYYE3CWIOqpct7pyf06EBcT7XY4xhgTcJYg6unDDTbvtDEmvFmCqKe3V9q808aY8GYJoh5s3mljTCSwBFEPlfNOW+0lY0w4swRRD5XzTvfvZPNOG2PClyWIOrJ5p40xkcISRB3ZvNPGmEhhCaKO0rPybd5pY0xEsARRB9v3HiUrp9DOHowxESGoCUJEJolItohsFpH7fWy/UUT2iMhK5/Zjr21/EpE1zu3qYMbpr8p5p79rCcIYEwGCVoJURKKBJ4ELgVxgmYikq+q6aru+pqp3VnvsxcAgYAAQB3wkIu+q6qFgxXsqJ+ad7mrzThtjIkMwzyCGAptVdauqHgdeBS7z87F9gU9UtUxVjwKrgElBitMvJ+adttIaxpgIEcwE0RHI8VrOddZV930RWSUib4hIZ2ddFjBJRJqKSBJwAdC5+gNFZJqIZIhIxp49ewIdfxXpWTbvtDEmsrjdST0P6Kqq/YH3gecAVPU94B3gC+AVYClQXv3BqjpLVdNUNS05OTloQVZUKPNW2rzTxpjIEswEkUfVX/2dnHUnqOo+VS1xFp8GBntt+6OqDlDVCwEBNgYx1lrZvNPGmEgUzASxDEgVkW4i0gS4Bkj33kFEvNtrLgXWO+ujRaStc78/0B94L4ix1srmnTbGRKKgXcWkqmUiciewCIgGnlXVtSLyIJChqunAXSJyKVAG7AdudB4eC3zqlLI4BFyvqmXBirU2Nu+0MSZSBfUbT1XfwdOX4L3uN173ZwAzfDyuGM+VTK77bLPNO22MiUxud1KHvPSVNu+0MSYyWYKohc07bYyJZJYganFi3mkrrWGMiUCWIGpxYt7p7jbvtDEm8liCqMHBY6V8nL2HS/rbvNPGmMhkCaIGC9cWcLy8gsus9pIxJkJZgqhBepbNO22MiWyWIHzYfaiYL7bs49JzU2zeaWNMxLIE4cOJeaeteckYE8EsQfiQnpVP3w4t6dmuhduhGGOMayxBVFM577R1ThtjIp0liGrm2bzTxhgDWIKoQlWZa/NOG2MMYAmiCpt32hhjvmUJwovNO22MMd+yBOGweaeNMaYqSxCOzG9s3mljjPFmCcLx9kqbd9oYY7xZgsDmnTbGGF8iPkHMXZHH8Ic+5MCxUr7Yso+5K/LcDskYY0JCRP9cnrsijxlzVlNUWg7A/qPHmTFnNQCXD7S+CGNMZIvoM4iZi7JPJIdKRaXlzFyU7VJExhgTOiI6QeQXFtVpvTHGRJKIThA1ldOwMhvGGBPhCWL6xN4kxEZXWZcQG830ib1disgYY0JHRHdSV3ZEz1yUTX5hESmJCUyf2Ns6qI0xhghPEOBJEpYQjDHmZBHdxGSMMaZmliCMMcb4ZAnCGGOMT5YgjDHG+GQJwhhjjE+iqm7HEBAisgfY4XYcpykJ2Ot2ECHEPo+q7PP4ln0WVZ3O53Gmqib72hA2CSIciEiGqqa5HUeosM+jKvs8vmWfRVXB+jysickYY4xPliCMMcb4ZAkitMxyO4AQY59HVfZ5fMs+i6qC8nlYH4Qxxhif7AzCGGOMT5YgjDHG+GQJogGJSGcRWSIi60RkrYjc7axvIyLvi8gm59/WznoRkSdEZLOIrBKRQe6+g8ATkWgRWSEi853lbiLylfOeXxORJs76OGd5s7O9q5txB4OIJIrIGyKyQUTWi8iICD82/sf5O1kjIq+ISHwkHR8i8qyI7BaRNV7r6nw8iMgNzv6bROSGusRgCaJhlQH3qmpfYDhwh4j0Be4HPlTVVOBDZxngIiDVuU0D/tnwIQfd3cB6r+U/AY+pak/gAHCLs/4W4ICz/jFnv3DzOLBQVc8CzsXzuUTksSEiHYG7gDRVPQeIBq4hso6P/wKTqq2r0/EgIm2A3wLDgKHAbyuTil9U1W4u3YC3gQuBbKCDs64DkO3c/zdwrdf+J/YLhxvQyTnIxwHzAcEzGjTG2T4CWOTcXwSMcO7HOPuJ2+8hgJ9FK2Bb9fcUwcdGRyAHaOP8f88HJkba8QF0BdbU93gArgX+7bW+yn6nutkZhEucU+CBwFdAe1UtcDbtBNo79yv/SCrlOuvCxd+AnwMVznJboFBVy5xl7/d74rNwth909g8X3YA9wH+cJrenRaQZEXpsqGoe8CjwDVCA5/87k8g9PirV9Xg4rePEEoQLRKQ58CZwj6oe8t6mnjQf9tcei8glwG5VzXQ7lhARAwwC/qmqA4GjfNt8AETOsQHgNINchidxpgDNOLm5JaI1xPFgCaKBiUgsnuTwkqrOcVbvEpEOzvYOwG5nfR7Q2evhnZx14WAUcKmIbAdexdPM9DiQKCKVU+F6v98Tn4WzvRWwryEDDrJcIFdVv3KW38CTMCLx2AAYD2xT1T2qWgrMwXPMROrxUamux8NpHSeWIBqQiAjwDLBeVf/qtSkdqLy64AY8fROV63/kXKEwHDjodXrZqKnqDFXtpKpd8XQ+LlbVHwBLgCud3ap/FpWf0ZXO/mHza1pVdwI5ItLbWfUdYB0ReGw4vgGGi0hT5++m8vOIyOPDS12Ph0XABBFp7ZyVTXDW+cftTphIugHn4TklXAWsdG6T8bSVfghsAj4A2jj7C/AksAVYjeeKDtffRxA+l7HAfOd+d+BrYDPwOhDnrI93ljc727u7HXcQPocBQIZzfMwFWkfysQH8DtgArAFeAOIi6fgAXsHT/1KK5wzzlvocD8DNzueyGbipLjFYqQ1jjDE+WROTMcYYnyxBGGOM8ckShDHGGJ8sQRhjjPHJEoQxxhifLEGYiCci5SKyUkSyRGS5iIw8xf6JInK7H8/7kYjUOpG8iEQ5VTjXiMhqEVkmIt2cbe+ISGLd3o0xgRNz6l2MCXtFqjoAQEQmAg8D59eyfyJwO/CPALz21XhKSfRX1QoR6YSnzAaqOjkAz29MvdkZhDFVtcRTRhoRaS4iHzpnFatF5DJnn0eAHs5Zx0xn3184+2SJyCNez3eViHwtIhtFZLSP1+sAFKhqBYCq5qpq5etvF5EkEbnNea2VIrJNRJY42yeIyFInvtedGl/GBIwNlDMRT0TK8Yw+jcfzhT1OVTOdmj5NVfWQiCQBX+Kpt38mnpHf5ziPvwj4NTBeVY+JSBtV3S8iHwGZqnqviEwGfqaq46u9difgM6AQzwjZF1V1hbNtO54RsXud5VhgMfBnYCme+kQXqepREfkFnlHFDwbrczKRx5qYjKnaxDQCeF5EzsFTvuAhERmDpyR5R74tr+xtPPAfVT0GoKr7vbZVFmTMxFPbvwpVzXXqL41zbh+KyFWq+qGP13kcT42heU413L7A555SRTTBkzSMCRhLEMZ4UdWlztlCMp46WcnAYFUtdX7Rx9fxKUucf8up4e9NVUuAd4F3RWQXcDmes4kTRORGPGcud1auAt5X1WvrGI8xfrM+CGO8iMhZeKa33IenZPRuJzlcgOcLGuAw0MLrYe8DN4lIU+c52tTh9QaJSIpzPwroD+yots9g4D7g+sq+CjzNXaNEpKezTzMR6VWnN2vMKdgZhDGQICIrnfsC3KCq5SLyEjBPRFbjqbK6AUBV94nI5+KZTP5dVZ0uIgOADBE5DrwD/NLP124HPCUicc7y18Dfq+1zJ56pN5c4zUkZqvpj56ziFa/HPgBsrNtbN6Zm1kltjDHGJ2tiMsYY45MlCGOMMT5ZgjDGGOOTJQhjjDE+WYIwxhjjkyUIY4wxPlmCMMYY49P/A8Y8unr+2r8nAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer to question 2: in summary, we can say the effect of batch size on the training process is not linear. It gives the model best performance around value of 400. And the model performed best with the batch size of 500 at an accuracy of 0.62870"
      ],
      "metadata": {
        "id": "G7lM0of3zEX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. we explore the effect of the hypermeter optimizer on the training process\n",
        "\n",
        "#we will try all availabel optimizers in keras\n",
        "optimizers = ['SGD', 'Adam', 'RMSProp', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']\n",
        "accuracyArr = []\n",
        "for i in range(len(optimizers)):\n",
        "  a = buildCNNModel(batchSize=600, optimizerStr=optimizers[i], learningRate=0.0013)\n",
        "  accuracyArr.append(a)\n",
        "  \n",
        "x = list(optimizers)\n",
        "bars = plt.bar(x, accuracyArr, width=0.8, color='g', alpha=0.5, align='center')\n",
        "plt.xlabel(\"Optimizers\")\n",
        "plt.ylabel('Model Accuracy')\n",
        "plt.title(\"Comparison among models using different optimizers in performance\")\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x(), yval + 0.025, \"{:.5f}\".format(yval))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xxV_wMaPkwp3",
        "outputId": "f7544b5f-bfc5-4215-8371-c8536837e0f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_60 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3059 - accuracy: 0.1023\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.3039 - accuracy: 0.1068\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.3025 - accuracy: 0.1108\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.3014 - accuracy: 0.1151\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.3004 - accuracy: 0.1215\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2996 - accuracy: 0.1258\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2990 - accuracy: 0.1288\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2983 - accuracy: 0.1335\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2976 - accuracy: 0.1401\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2969 - accuracy: 0.1454\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2960 - accuracy: 0.1495\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2950 - accuracy: 0.1532\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2940 - accuracy: 0.1547\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2930 - accuracy: 0.1536\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2921 - accuracy: 0.1547\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2910 - accuracy: 0.1552\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2899 - accuracy: 0.1562\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2886 - accuracy: 0.1565\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2871 - accuracy: 0.1575\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2855 - accuracy: 0.1549\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2838 - accuracy: 0.1521\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2820 - accuracy: 0.1515\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2800 - accuracy: 0.1530\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2780 - accuracy: 0.1546\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2757 - accuracy: 0.1584\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2754 - accuracy: 0.1498\n",
            "Test loss: 2.275362014770508\n",
            "Test accuracy: 0.14980000257492065\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_63 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.9352 - accuracy: 0.3031\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.6640 - accuracy: 0.4019\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.5639 - accuracy: 0.4370\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4913 - accuracy: 0.4646\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4277 - accuracy: 0.4887\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3776 - accuracy: 0.5074\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3298 - accuracy: 0.5242\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3091 - accuracy: 0.5326\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2782 - accuracy: 0.5457\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2499 - accuracy: 0.5529\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2344 - accuracy: 0.5607\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2159 - accuracy: 0.5668\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1880 - accuracy: 0.5785\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1752 - accuracy: 0.5820\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1491 - accuracy: 0.5926\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1419 - accuracy: 0.5957\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.1232 - accuracy: 0.6024\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.1123 - accuracy: 0.6071\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0964 - accuracy: 0.6112\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.0827 - accuracy: 0.6167\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.0745 - accuracy: 0.6204\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0587 - accuracy: 0.6271\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0509 - accuracy: 0.6306\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0384 - accuracy: 0.6357\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0303 - accuracy: 0.6349\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1341 - accuracy: 0.6009\n",
            "Test loss: 1.1340594291687012\n",
            "Test accuracy: 0.6008999943733215\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_66 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_22 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_45 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 2s 12ms/step - loss: 2.0789 - accuracy: 0.2429\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.8334 - accuracy: 0.3449\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.7194 - accuracy: 0.3879\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.6489 - accuracy: 0.4141\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.5741 - accuracy: 0.4420\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.5207 - accuracy: 0.4619\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4707 - accuracy: 0.4792\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4313 - accuracy: 0.4943\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3894 - accuracy: 0.5085\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.3584 - accuracy: 0.5213\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.3315 - accuracy: 0.5307\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3022 - accuracy: 0.5427\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2751 - accuracy: 0.5540\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2545 - accuracy: 0.5579\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2319 - accuracy: 0.5679\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2176 - accuracy: 0.5723\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 14ms/step - loss: 1.1843 - accuracy: 0.5859\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.1742 - accuracy: 0.5855\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 15ms/step - loss: 1.1543 - accuracy: 0.5958\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1377 - accuracy: 0.6012\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.1229 - accuracy: 0.6067\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.1080 - accuracy: 0.6129\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.0878 - accuracy: 0.6186\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0728 - accuracy: 0.6243\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.0660 - accuracy: 0.6260\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2943 - accuracy: 0.5586\n",
            "Test loss: 1.2943297624588013\n",
            "Test accuracy: 0.5586000084877014\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_69 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_23 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_46 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_47 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3055 - accuracy: 0.0781\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3047 - accuracy: 0.0823\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3039 - accuracy: 0.0870\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3032 - accuracy: 0.0915\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3025 - accuracy: 0.0976\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3018 - accuracy: 0.1047\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3011 - accuracy: 0.1118\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3005 - accuracy: 0.1188\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2998 - accuracy: 0.1248\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2992 - accuracy: 0.1310\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2986 - accuracy: 0.1369\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2980 - accuracy: 0.1423\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2973 - accuracy: 0.1472\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2967 - accuracy: 0.1527\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2960 - accuracy: 0.1570\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2953 - accuracy: 0.1611\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2946 - accuracy: 0.1645\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2938 - accuracy: 0.1678\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2931 - accuracy: 0.1710\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2923 - accuracy: 0.1741\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2914 - accuracy: 0.1766\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2905 - accuracy: 0.1798\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2896 - accuracy: 0.1830\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2886 - accuracy: 0.1848\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2877 - accuracy: 0.1883\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.2872 - accuracy: 0.1850\n",
            "Test loss: 2.287158727645874\n",
            "Test accuracy: 0.1850000023841858\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_72 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_48 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_49 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_24 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_48 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_49 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3010 - accuracy: 0.1158\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3003 - accuracy: 0.1195\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2995 - accuracy: 0.1236\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2987 - accuracy: 0.1275\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2977 - accuracy: 0.1372\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2965 - accuracy: 0.1448\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2949 - accuracy: 0.1558\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2928 - accuracy: 0.1632\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2900 - accuracy: 0.1787\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2865 - accuracy: 0.1920\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2818 - accuracy: 0.2096\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2754 - accuracy: 0.2201\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2665 - accuracy: 0.2321\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2535 - accuracy: 0.2402\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2342 - accuracy: 0.2419\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.2067 - accuracy: 0.2440\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.1705 - accuracy: 0.2394\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.1284 - accuracy: 0.2386\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.0901 - accuracy: 0.2452\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.0606 - accuracy: 0.2498\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.0391 - accuracy: 0.2566\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.0234 - accuracy: 0.2624\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.0110 - accuracy: 0.2663\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.0004 - accuracy: 0.2707\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.9909 - accuracy: 0.2759\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9855 - accuracy: 0.2811\n",
            "Test loss: 1.9854861497879028\n",
            "Test accuracy: 0.28110000491142273\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_75 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_50 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_51 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.9999 - accuracy: 0.2814\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.7387 - accuracy: 0.3796\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.6217 - accuracy: 0.4157\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.5448 - accuracy: 0.4391\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4894 - accuracy: 0.4625\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4579 - accuracy: 0.4738\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4259 - accuracy: 0.4879\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4028 - accuracy: 0.4977\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3761 - accuracy: 0.5066\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3535 - accuracy: 0.5159\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.3370 - accuracy: 0.5239\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3191 - accuracy: 0.5293\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.3006 - accuracy: 0.5358\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2855 - accuracy: 0.5450\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2669 - accuracy: 0.5514\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2606 - accuracy: 0.5531\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2475 - accuracy: 0.5583\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2278 - accuracy: 0.5664\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2248 - accuracy: 0.5679\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2115 - accuracy: 0.5728\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 15ms/step - loss: 1.2017 - accuracy: 0.5753\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 14ms/step - loss: 1.1938 - accuracy: 0.5794\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1820 - accuracy: 0.5830\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1708 - accuracy: 0.5861\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1665 - accuracy: 0.5879\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2109 - accuracy: 0.5707\n",
            "Test loss: 1.2109243869781494\n",
            "Test accuracy: 0.5706999897956848\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_78 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_52 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_53 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_80 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_26 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_52 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_53 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 2s 13ms/step - loss: 2.0565 - accuracy: 0.2532\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.7407 - accuracy: 0.3783\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.6152 - accuracy: 0.4240\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.5272 - accuracy: 0.4546\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4565 - accuracy: 0.4750\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4081 - accuracy: 0.4951\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3604 - accuracy: 0.5127\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 14ms/step - loss: 1.3370 - accuracy: 0.5248\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 15ms/step - loss: 1.2929 - accuracy: 0.5407\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2633 - accuracy: 0.5523\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2401 - accuracy: 0.5600\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2115 - accuracy: 0.5709\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1836 - accuracy: 0.5816\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1710 - accuracy: 0.5865\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1375 - accuracy: 0.5975\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1237 - accuracy: 0.6042\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0975 - accuracy: 0.6141\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0838 - accuracy: 0.6188\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0667 - accuracy: 0.6261\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0523 - accuracy: 0.6290\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0386 - accuracy: 0.6345\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0243 - accuracy: 0.6418\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0022 - accuracy: 0.6498\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9846 - accuracy: 0.6532\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9717 - accuracy: 0.6595\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1413 - accuracy: 0.5976\n",
            "Test loss: 1.1412888765335083\n",
            "Test accuracy: 0.597599983215332\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_81 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_54 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_82 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_55 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_27 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_54 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_55 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 2s 13ms/step - loss: 2.3027 - accuracy: 0.0991\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 1s 14ms/step - loss: 2.3026 - accuracy: 0.0985\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 1s 14ms/step - loss: 2.3026 - accuracy: 0.0967\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 1s 14ms/step - loss: 2.3026 - accuracy: 0.0973\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3026 - accuracy: 0.0977\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0963\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0983\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0970\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0980\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3026 - accuracy: 0.0955\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0976\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0983\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3026 - accuracy: 0.0989\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0985\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0984\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0953\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0988\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0962\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0961\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0993\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0985\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0982\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3026 - accuracy: 0.0985\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0975\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.3026 - accuracy: 0.0968\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.1000\n",
            "Test loss: 2.3025856018066406\n",
            "Test accuracy: 0.10000000149011612\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer to question 3: \n",
        "# We try the hyperparameter of optimizer to test their influence on the accuracy of the model on testing data\n",
        "# From the bar graph, we can see Adam, RMSProp, Adamax, and Nadam give models much better performance than SGD, Adadelta, Adagrad, and Ftrl.\n",
        "# The performance of models using Adam, RMSProp, Adamax, and Nadam optimizers are close. Among them, the model using Adam gives the best performance with an accuracy of 0.60090"
      ],
      "metadata": {
        "id": "umlVp_a60hVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. build and test the equivalent feed forward network\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "# first convert each input which is a 3d matrix into a vector\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(32,32,3)))\n",
        "#layer 1\n",
        "model.add(tf.keras.layers.Dense(6))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "#layer 2\n",
        "model.add(tf.keras.layers.Dense(16))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "#layer 3\n",
        "model.add(tf.keras.layers.Dense(120))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "#layer 4\n",
        "model.add(tf.keras.layers.Dense(84))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "#output layer\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "#compile the model with certain configuration of loss function, optimizer and its learning rate, and result metrics\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_x,\n",
        "    train_labels, \n",
        "    batch_size=500,\n",
        "    epochs=25)\n",
        "# test the model performance\n",
        "score = model.evaluate(test_x, test_labels)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unYn8a5PleCQ",
        "outputId": "2d8be56c-f963-40cd-a205-ece757a33afb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 18438     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                112       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 120)               2040      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 120)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,604\n",
            "Trainable params: 31,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 2.0989 - accuracy: 0.1887\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 1.9503 - accuracy: 0.2584\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 1.9178 - accuracy: 0.2729\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 1.9054 - accuracy: 0.2784\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 1.9025 - accuracy: 0.2837\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 1.8900 - accuracy: 0.2913\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 1.8808 - accuracy: 0.2982\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 1.8730 - accuracy: 0.3060\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 1.8645 - accuracy: 0.3102\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 1.8659 - accuracy: 0.3108\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.8543 - accuracy: 0.3130\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 1.8470 - accuracy: 0.3202\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 1.8436 - accuracy: 0.3198\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 1.8410 - accuracy: 0.3233\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 1.8319 - accuracy: 0.3276\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 1.8329 - accuracy: 0.3266\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 1.8304 - accuracy: 0.3288\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 1.8202 - accuracy: 0.3334\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 1.8169 - accuracy: 0.3374\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 1.8157 - accuracy: 0.3360\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 1.8151 - accuracy: 0.3356\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 2s 16ms/step - loss: 1.8072 - accuracy: 0.3391\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 2s 17ms/step - loss: 1.8041 - accuracy: 0.3402\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 1.8019 - accuracy: 0.3413\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 1.8039 - accuracy: 0.3417\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.8295 - accuracy: 0.3289\n",
            "Test loss: 1.8294607400894165\n",
            "Test accuracy: 0.328900009393692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer to question 4: \n",
        "\n",
        "#a. from the console, we can see the feed forward model didn't perform well in testing dataset. It only had an accuracy of 0.32890\n",
        "\n",
        "# b. Feed forward network has more parameters than LeNet CNN in the first layer while LeNet CNN has more parameters than feed forward network in the middle layer, and they have same number of parameters in the last two layers. Specifically, in feed forward network, there are 18438 parameters in the frist layer, 112 parameters in the second layer, 2040 parameters in the third layer, 10164 parameters in the fourth layer, and 850 parameters in the output layer. In contrast, in LeNet CNN, there are only 456 parameters in the frist layer, 2416 parameters in the third layer, 48120 parameters in the fifth layer, 10164 parameters in the sixth layer, and 850 parameters in the output layer.\n",
        "\n",
        "# I don't think the huge amount of parameters in the first layer of the feed forward network is worthy. The huge amount of the parameters is due to the big size of the input. Actually, not all pixeles in the input image contains useful information and more importantly representing them in a vector loses their spatial relationship between the pixels. As we can see, there are less parameters in middle layer in the feed forward model, which indicates this model extract less features from the input than LeNet CNN. Hence, I think using so many parameters to learn so big inputs in feed forward model is not only unworthy but also not harmful. Instead, we should more efficiently extract features from input images using either CNN or transfer.\n"
      ],
      "metadata": {
        "id": "21SGJ2uUzDPT"
      }
    }
  ]
}